Welcome to LING-462/COSC-482 Statistical Machine Translation (Spring
2018)!

### Summary

After more than 60 years since Machine Translation (MT) research started
at Georgetown, this area of Natural Language Processing (NLP) research
is more active than ever. In this course we explore the data-driven
approaches to translate human language with computers that supplanted
rule-based approaches in the past quarter century. First, we lay
foundations for the course with statistical NLP relevant to MT and
corpus preparation. Next, we start exploring statistical MT (SMT) --
from word-based models to phrase-based models to tree-based models. We
will then cover domain-adaptation, incremental learning and how to
integrate linguistic information. We will learn how to evaluate system
output with automatic and human evaluation methods.

Recently, deep learning-based approaches have proven to produce superior
translation quality compared to SMT. We will investigate the current
state-of-the-art in neural MT (NMT) and contrast its strength and
weaknesses with SMT.

Machine translation does not exist in a vacuum; it is now used to
provide draft translations for human translators and is embedded in
other NLP systems. With better quality, raw MT is increasingly used in
in written and spoken human communication. We study the adaptation of MT
for the most common applications.

### Lectures

Thu 3:30pm - 6:00pm

### Instructor

Achim Ruopp\
E-Mail: achim.ruopp(at)georgetown.edu

### Course prerequisites

Basic Python programming skills are required (for example satisfied by
LING-362: Intro to NLP; COSC/LING-272: Algorithms for NLP;
COSC/LING-572: Empirical Methods in Natural Language Processing or
permission of instructor)

### In-class presentation: Language in ten minutes

How are you going to build a machine translation system unless you know
at least a little bit about language? You will be required to give a
short presentation (\~10 minutes) on a particular language, e.g.,
Arabic, Chinese, Czech, Hindi, Italian, or Maltese.

The language must not be your first native tongue. If you are fluent or
very familiar with the language we encourage you to pick one that you
are not so familiar with. The language cannot be English.

You should prepare three to six slides for your presentation, covering
language facts (demographics, location, etc.) important linguistic
characteristics (orthography, morphology, syntax) and computational
efforts such as resources, tools, papers. For instance, how many entries
are there about the language in the [MT
Archive](http://www.mt-archive.info/) and what are they generally about?
Which parallel corpora are available between the language and English?
What other linguistic resources and tools are available that could aid
machine translation? Be creative and have fun. Asking for help from
native speakers or language experts is great. But you are ultimately
responsible for the presentation.

[Nizar Habash](http://www.nizarhabash.com/) inspired this assignment.
For inspiration, check out:

-   [Examples from Nizar's
    class](https://sites.google.com/site/comse6998machinetranslation/language-in-10-minutes)
-   [Ethnologue](http://www.ethnologue.com/)
-   [Omniglot](http://www.omniglot.com/)
-   [About World Languages](http://www.aboutworldlanguages.com/)
-   [Machine Translation Archive](http://www.mt-archive.info/)
-   [World Atlas of Language Structures](http://wals.info/)

We will grade on clarity and detail. Did you learn something really
cool? Tell us!

Adapted from <http://mt-class.org/jhu>

### Textbooks

We will use the textbook Statistical Machine Translation by Philipp
Koehn (Cambridge University Press, ISBN-10: 0521874157, ISBN-13:
978-0521874151) which is available from the
[Georgetown Library](https://www.library.georgetown.edu/)
(identified in the assigned
reading as \"Koehn SMT\"). We will also use book Neural Machine
Translation (3rd draft) by Philipp Koehn available
[here](http://mt-class.org/jhu/assets/nmt-book.pdf) (identified in the
assigned reading as \"Koehn NMT\"). Other reading materials are provided
as links in the course plan.


